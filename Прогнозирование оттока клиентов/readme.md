# Отток клиентов

## Статус проекта: завершён

## Описание проекта

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

## Цель исследования

Постройте модель с предельно большим значением F1-меры

## Навыки и инструменты

- **pandas**
- **matplotlib**
- sklearn.metrics.**shuffle**
- sklearn.metrics.**accuracy_score**
- sklearn.metrics.**f1_score**
- sklearn.metrics.**roc_auc_score**
- sklearn.metrics.**roc_curve**
- sklearn.model_selection.**train_test_split**
- sklearn.preprocessing.**StandardScaler**
- sklearn.ensemble.**RandomForestClassifier**
- sklearn.tree.**DecisionTreeClassifier**
- sklearn.linear_model.**LogisticRegression**
- sklearn.dummy.**DummyClassifier**

## Описание данных

### Признаки
- RowNumber — индекс строки в данных
- CustomerId — уникальный идентификатор клиента
- Surname — фамилия
- CreditScore — кредитный рейтинг
- Geography — страна проживания
- Gender — пол
- Age — возраст
- Tenure — сколько лет человек является клиентом банка
- Balance — баланс на счёте
- NumOfProducts — количество продуктов банка, используемых клиентом
- HasCrCard — наличие кредитной карты
- IsActiveMember — активность клиента
- EstimatedSalary — предполагаемая зарплата

### Целевой признак
- Exited — факт ухода клиента

## Вывод по итогам исследования

- #### Подготовленны и исследованы данные. В исходных данных наблюдался дисбаланс классов, 80% ответов целевого признака были "0" и 20% позитивными.

  #### На несбалансированных исходных данных модели показывают низкое значние F1-меры, что свидетельствует о низком качестве моделей

  - F1 модели Logistic Regression: 0.33
  - F1 модели Random Forest: 0.59
  - F1 модели Decision Tree: 0.57

  #### Был устранен дисбаланс классов в обучающей выборке методом upsampling и downsampling.

  #### На сбалансированных данных модели показали результат выше, чем на несбалансированной выборке. Лучшие метрики у модели Random Forest (Количество деревьев: 110, Глубина дерева: 10), обученной на сбалансированных данных методом upsampling. Удалось достичь значения F1-меры 0,628 на валидационной выборке.

  - Точность: 0.5063897763578274
  - Полнота: 0.7583732057416268

  #### На тестовой выборке лучшая модель показала метрики:

  - F1 модели : 0.608
  - Точность: 0.558
  - Полнота: 0.669
  - AUC-ROC: 0.855
